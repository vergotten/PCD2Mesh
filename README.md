# PCD2Mesh
Joint Layout, Object Pose and Mesh Reconstruction Method from Scanned Point Clouds with Restoration of Missing Points

Current work proposes a novel method for Joint Layout, Object Pose, and Mesh Reconstruction from scanned point clouds, with the restoration of missing points. The goal of this research is to develop an advanced approach that can generate accurate and complete 3D models from point cloud data obtained from real-world environments. The proposed method leverages state-of-the-art neural network architectures, including PointNeXt and Stratified Transformer, to accomplish the task. PointNeXt is used for feature extraction, while Stratified Transformer is used for joint feature representation learning. By combining these two networks, the proposed method can effectively encode the complex geometries of the 3D scenes and generate high-quality reconstructions. One of the key contributions of this thesis is that it addresses the issue of missing points. The proposed method includes a point restoration component that uses a combination of convolutional neural networks (CNNs) and graph convolutional networks (GCNs) to predict the missing points. This enables the method to reconstruct complete and accurate models, even when some of the original data is missing. The proposed method is evaluated using a range of benchmark datasets and compared against several state-of-the-art approaches. Overall, this thesis presents a novel approach for Joint Layout, Object Pose, and Mesh Reconstruction from scanned point clouds that leverages the latest neural network architectures and addresses the challenge of missing point data. The proposed method has the potential to be a valuable tool in a range of applications, including architecture, engineering, and construction, as well as augmented and mixed reality.
